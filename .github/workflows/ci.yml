# .github/workflows/ci.yml
name: Build, Test, and Push Docker Image

on:
  push:
    branches: [ "main" ]

env:
  DOCKER_IMAGE: attiquers/todoapp # CHANGE THIS to your actual Docker Hub username
  EKS_CLUSTER_NAME: todo-app-cluster
  AWS_REGION: us-east-1

jobs:
  # -----------------------------------------------------------
  # JOB 1: Run Linters
  # -----------------------------------------------------------
  lint:
    name: "Run Linter (Pint)"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: shivammathur/setup-php@v2
        with:
          php-version: '8.2'
          tools: composer
      - run: composer install --prefer-dist --no-progress
      - run: echo "Skipping Pint, not installed. Add 'laravel/pint' to run."

  # -----------------------------------------------------------
  # JOB 2: Run Tests
  # -----------------------------------------------------------
  test:
    name: "Run Tests"
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v4
      - run: cp .env.example .env
      - name: Set Sail DB Variables
        run: |
          sed -i 's/DB_HOST=127.0.0.1/DB_HOST=mysql/' .env
          sed -i 's/DB_DATABASE=laravel/DB_DATABASE=TodoApp/' .env
          sed -i 's/DB_USERNAME=root/DB_USERNAME=sail/' .env
          sed -i 's/DB_PASSWORD=/DB_PASSWORD=password/' .env
      - run: docker run --rm -v $(pwd):/app -w /app laravelsail/php82-composer composer install
      - run: ./vendor/bin/sail up -d
      - name: Test (with DB service)
        run: |
          echo "Waiting for MySQL to be healthy..."
          for i in {1..30}; do
            if ./vendor/bin/sail ps | grep 'mysql' | grep -q '(healthy)'; then break; fi
            echo "Waiting... ($i/30)"
            sleep 2
          done
      - run: ./vendor/bin/sail artisan key:generate
      - run: ./vendor/bin/sail artisan migrate
      - run: ./vendor/bin/sail artisan test

  # -----------------------------------------------------------
  # JOB 3: Build and Push
  # -----------------------------------------------------------
  build-and-push:
    name: "Build and Push to Docker Hub"
    runs-on: ubuntu-latest
    needs: test
    steps:
      - uses: actions/checkout@v4
      - uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }} 
          password: ${{ secrets.DOCKERHUB_TOKEN }}      
      - uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile.prod
          push: true
          tags: ${{ secrets.DOCKERHUB_USERNAME }}/todoapp:latest

  # -----------------------------------------------------------
  # JOB 4: Smart Infrastructure Provisioning
  # -----------------------------------------------------------
  provision-infra:
    name: "Provision Infrastructure (Terraform)"
    runs-on: ubuntu-latest
    needs: test
    steps:
      - uses: actions/checkout@v4
      - uses: hashicorp/setup-terraform@v3
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Check if Cluster Exists
        id: check-cluster
        run: |
          if aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }} > /dev/null 2>&1; then
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Terraform Init
        if: steps.check-cluster.outputs.exists == 'false'
        run: terraform init
        working-directory: ./infra

      - name: Terraform Validate
        if: steps.check-cluster.outputs.exists == 'false'
        run: terraform validate
        working-directory: ./infra

      - name: Terraform Apply
        if: steps.check-cluster.outputs.exists == 'false'
        timeout-minutes: 30 
        working-directory: ./infra
        run: terraform apply -auto-approve

  # -----------------------------------------------------------
  # JOB 5: Deploy to AWS EKS (FIXED MIGRATION LOGIC)
  # -----------------------------------------------------------
  deploy-to-eks:
    name: "Deploy to AWS EKS"
    runs-on: ubuntu-latest
    needs: [build-and-push, provision-infra]
    steps:
      - uses: actions/checkout@v4
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Update Kubeconfig
        run: aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER_NAME }}

      - name: Deploy to Kubernetes
        run: |
          kubectl apply -f k8s/deployment.yaml
          kubectl rollout restart deployment/todo-app
          kubectl rollout status deployment/todo-app

      - name: Run Database Migrations
        run: |
          echo "Starting Migration Process..."
          
          # Loop 5 times to try and find a valid, stable pod
          for i in {1..5}; do
            # 1. Get pods
            # 2. Filter for only "Running" pods
            # 3. Sort by CreationTimestamp (Oldest first, Newest last)
            # 4. JSONPath picks the last item [-1] which is the NEWEST pod
            POD_NAME=$(kubectl get pods -l app=todo-app --field-selector=status.phase=Running --sort-by=.metadata.creationTimestamp -o jsonpath="{.items[-1].metadata.name}")
            
            if [ -n "$POD_NAME" ]; then
              echo "Attempting migration on NEWEST pod: $POD_NAME"
              
              # Try to execute. If successful, exit script with success (0)
              if kubectl exec $POD_NAME -- php artisan migrate --force; then
                echo "✅ Database migrated successfully!"
                exit 0
              fi
              
              echo "⚠ Exec failed (Pod might have just terminated). Retrying..."
            else
              echo "Waiting for a running pod... ($i/5)"
            fi
            
            sleep 10
          done
          
          echo "❌ Failed to migrate database after multiple attempts."
          exit 1

  # -----------------------------------------------------------
  # JOB 6: Post-Deploy Smoke Tests
  # -----------------------------------------------------------
  smoke-test:
    name: "Smoke Test (Health Check)"
    runs-on: ubuntu-latest
    needs: deploy-to-eks
    steps:
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      - run: aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER_NAME }}
      - name: Check App URL
        run: |
          SERVICE_URL=$(kubectl get svc todo-app-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          echo "Checking URL: http://$SERVICE_URL"
          sleep 30
          if curl -s --head --request GET "http://$SERVICE_URL" | grep "200 OK" > /dev/null; then 
             echo "✅ Smoke Test Passed!"
          else
             echo "⚠ Smoke Test Warning: App might still be propagating."
          fi